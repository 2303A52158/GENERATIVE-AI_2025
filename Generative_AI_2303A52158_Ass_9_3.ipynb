{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd2wsulV8x4cJIfZaNrn7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52158/GENERATIVE-AI_2025/blob/main/Generative_AI_2303A52158_Ass_9_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Design a multilayer ANN architecture to identify the hand-written digits using the\n",
        "Keras deep learning library. Consider the MNIST data set**\n",
        "\n",
        "**2. (1 ponto) Calculate the accuracy with training and testing data**\n",
        "\n",
        "**3. (1 ponto) Also, change the architecture by tuning no. of hidden layers, no. of hidden neurons\n",
        "and activation functions in hidden layer. Identify best architecture in terms of testing accuracy**\n",
        "\n",
        "                    Tabela 1: ANN Architecture\n",
        "          Layer          Neurons Activation Function\n",
        "      Hidden Layer - 1     128         swish\n",
        "      Hidden Layer - 2     128         swish\n",
        "      Hidden Layer - 3     128         swish\n",
        "\n",
        "                    Tabela 2: Training Parameters\n",
        "          epochs batch size error metric Optimizer\n",
        "            30        32      accuracy     adam"
      ],
      "metadata": {
        "id": "jc0gnRWudz8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPBrjYHfdvJV",
        "outputId": "4d5e35c3-ec19-457a-cfba-93431ac76902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.4151 - val_accuracy: 0.9630 - val_loss: 0.1126\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.1017 - val_accuracy: 0.9722 - val_loss: 0.0905\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0636 - val_accuracy: 0.9754 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.0448 - val_accuracy: 0.9752 - val_loss: 0.0857\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0378 - val_accuracy: 0.9734 - val_loss: 0.0927\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0277 - val_accuracy: 0.9806 - val_loss: 0.0791\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0223 - val_accuracy: 0.9756 - val_loss: 0.0985\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0224 - val_accuracy: 0.9809 - val_loss: 0.0841\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0163 - val_accuracy: 0.9806 - val_loss: 0.0816\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0131 - val_accuracy: 0.9728 - val_loss: 0.1366\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0183 - val_accuracy: 0.9776 - val_loss: 0.1075\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.9799 - val_loss: 0.1011\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0148 - val_accuracy: 0.9790 - val_loss: 0.1246\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0126 - val_accuracy: 0.9770 - val_loss: 0.1225\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.9753 - val_loss: 0.1396\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0166 - val_accuracy: 0.9778 - val_loss: 0.1285\n",
            "Epoch 17/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0103 - val_accuracy: 0.9777 - val_loss: 0.1347\n",
            "Epoch 18/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0111 - val_accuracy: 0.9771 - val_loss: 0.1353\n",
            "Epoch 19/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.9771 - val_loss: 0.1265\n",
            "Epoch 20/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9765 - val_loss: 0.1357\n",
            "Epoch 21/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9763 - val_loss: 0.1401\n",
            "Epoch 22/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9792 - val_loss: 0.1368\n",
            "Epoch 23/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0100 - val_accuracy: 0.9779 - val_loss: 0.1464\n",
            "Epoch 24/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0158 - val_accuracy: 0.9777 - val_loss: 0.1453\n",
            "Epoch 25/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0110 - val_accuracy: 0.9787 - val_loss: 0.1401\n",
            "Epoch 26/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9691 - val_loss: 0.2154\n",
            "Epoch 27/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0109 - val_accuracy: 0.9804 - val_loss: 0.1571\n",
            "Epoch 28/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9776 - val_loss: 0.1737\n",
            "Epoch 29/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0087 - val_accuracy: 0.9801 - val_loss: 0.1667\n",
            "Epoch 30/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9769 - val_loss: 0.1821\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9769\n",
            "Confusion Matrix:\n",
            "[[ 961    0    2    0    1    1   10    3    1    1]\n",
            " [   0 1120    3    1    2    2    2    2    3    0]\n",
            " [   0    0 1021    2    1    0    1    4    3    0]\n",
            " [   0    0    6  981    0    2    0    8    2   11]\n",
            " [   0    0    3    0  963    0    4    3    2    7]\n",
            " [   0    0    0   13    0  864    4    1    4    6]\n",
            " [   1    3    1    1    8    4  935    0    4    1]\n",
            " [   0    2   14    0    1    0    0 1006    2    3]\n",
            " [   1    0   13    5    2    3    3    4  938    5]\n",
            " [   0    2    0    5   10    2    1    7    2  980]]\n",
            "Classification Report:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "Predicted Digit: 5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='swish'),\n",
        "    Dense(128, activation='swish'),\n",
        "    Dense(128, activation='swish'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "report = classification_report(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "model.save(\"mnist_model.h5\")\n",
        "\n",
        "def predict_digit(image):\n",
        "    model = tf.keras.models.load_model(\"mnist_model.h5\")\n",
        "    image = image.reshape(1, 28, 28) / 255.0\n",
        "    prediction = model.predict(image)\n",
        "    return np.argmax(prediction)\n",
        "\n",
        "sample_image = X_test[0]\n",
        "predicted_digit = predict_digit(sample_image)\n",
        "print(f\"Predicted Digit: {predicted_digit}\")\n"
      ]
    }
  ]
}