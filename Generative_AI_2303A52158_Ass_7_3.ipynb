{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNubl6THNQWBiyLYzejwEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52158/GENERATIVE-AI_2025/blob/main/Generative_AI_2303A52158_Ass_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Design a multilayer ANN architecture according to the requirements shown below.\n",
        "Train, test, save (.h5) and deploy the model to diagnose diabatic disease using the Keras deep\n",
        "learning library**\n",
        "\n",
        "**2. (1 ponto) Calculate training and testing accuracy, build confusion matrix, also calculate recall,\n",
        "precision and F1-score.**\n",
        "\n",
        "**3. (1 ponto) Build the application by loading the saved ANN model.**\n",
        "\n",
        "                        Tabela 1: ANN Architecture\n",
        "\n",
        "                  Layer         Neurons   Activation Function\n",
        "              Hidden Layer-1      12             swish\n",
        "              Hidden Layer-2      25             swish\n",
        "              Hidden Layer-3      15             swish\n",
        "                        Tabela 2: Training Parameters\n",
        "\n",
        "            epochs batch-size error-metric Optimizer\n",
        "              300       16      accuracy    adagrad"
      ],
      "metadata": {
        "id": "piCik2ZkPPIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "dataset_path = \"/content/Housing (1).csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='swish', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(25, activation='swish'),\n",
        "    tf.keras.layers.Dense(15, activation='swish'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUC7j1y2QJVk",
        "outputId": "cadffb6d-7417-4664-ae4a-981e19a27519"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3583 - loss: 0.6786 - val_accuracy: 0.3670 - val_loss: 0.6696\n",
            "Epoch 2/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3645 - loss: 0.6507 - val_accuracy: 0.3945 - val_loss: 0.6493\n",
            "Epoch 3/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4240 - loss: 0.6375 - val_accuracy: 0.3853 - val_loss: 0.6317\n",
            "Epoch 4/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4349 - loss: 0.6304 - val_accuracy: 0.3670 - val_loss: 0.6160\n",
            "Epoch 5/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4075 - loss: 0.5981 - val_accuracy: 0.3670 - val_loss: 0.6024\n",
            "Epoch 6/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4462 - loss: 0.5924 - val_accuracy: 0.3761 - val_loss: 0.5892\n",
            "Epoch 7/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4364 - loss: 0.5827 - val_accuracy: 0.3761 - val_loss: 0.5764\n",
            "Epoch 8/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4430 - loss: 0.5617 - val_accuracy: 0.3761 - val_loss: 0.5642\n",
            "Epoch 9/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4303 - loss: 0.5456 - val_accuracy: 0.3853 - val_loss: 0.5530\n",
            "Epoch 10/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4643 - loss: 0.5106 - val_accuracy: 0.3853 - val_loss: 0.5420\n",
            "Epoch 11/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4707 - loss: 0.5282 - val_accuracy: 0.3853 - val_loss: 0.5313\n",
            "Epoch 12/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4659 - loss: 0.5328 - val_accuracy: 0.3853 - val_loss: 0.5210\n",
            "Epoch 13/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4643 - loss: 0.4986 - val_accuracy: 0.3853 - val_loss: 0.5110\n",
            "Epoch 14/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4635 - loss: 0.4631 - val_accuracy: 0.3853 - val_loss: 0.5014\n",
            "Epoch 15/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4541 - loss: 0.4569 - val_accuracy: 0.3945 - val_loss: 0.4917\n",
            "Epoch 16/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4549 - loss: 0.4854 - val_accuracy: 0.3945 - val_loss: 0.4819\n",
            "Epoch 17/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4344 - loss: 0.4578 - val_accuracy: 0.3945 - val_loss: 0.4726\n",
            "Epoch 18/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4692 - loss: 0.4661 - val_accuracy: 0.3945 - val_loss: 0.4631\n",
            "Epoch 19/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4374 - loss: 0.4227 - val_accuracy: 0.3945 - val_loss: 0.4534\n",
            "Epoch 20/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4275 - loss: 0.4581 - val_accuracy: 0.3945 - val_loss: 0.4439\n",
            "Epoch 21/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4620 - loss: 0.4397 - val_accuracy: 0.3945 - val_loss: 0.4346\n",
            "Epoch 22/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4262 - loss: 0.4337 - val_accuracy: 0.4037 - val_loss: 0.4251\n",
            "Epoch 23/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4293 - loss: 0.4306 - val_accuracy: 0.4037 - val_loss: 0.4160\n",
            "Epoch 24/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4647 - loss: 0.4400 - val_accuracy: 0.3945 - val_loss: 0.4066\n",
            "Epoch 25/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4413 - loss: 0.4066 - val_accuracy: 0.3945 - val_loss: 0.3969\n",
            "Epoch 26/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4436 - loss: 0.3706 - val_accuracy: 0.3945 - val_loss: 0.3880\n",
            "Epoch 27/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4634 - loss: 0.3443 - val_accuracy: 0.3945 - val_loss: 0.3790\n",
            "Epoch 28/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4274 - loss: 0.3921 - val_accuracy: 0.3945 - val_loss: 0.3702\n",
            "Epoch 29/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4294 - loss: 0.3604 - val_accuracy: 0.3945 - val_loss: 0.3611\n",
            "Epoch 30/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4746 - loss: 0.3293 - val_accuracy: 0.3945 - val_loss: 0.3522\n",
            "Epoch 31/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4604 - loss: 0.3405 - val_accuracy: 0.3945 - val_loss: 0.3434\n",
            "Epoch 32/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4181 - loss: 0.3210 - val_accuracy: 0.3945 - val_loss: 0.3343\n",
            "Epoch 33/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4305 - loss: 0.3206 - val_accuracy: 0.3945 - val_loss: 0.3253\n",
            "Epoch 34/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4338 - loss: 0.3057 - val_accuracy: 0.3945 - val_loss: 0.3159\n",
            "Epoch 35/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4297 - loss: 0.2770 - val_accuracy: 0.3945 - val_loss: 0.3064\n",
            "Epoch 36/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4462 - loss: 0.2658 - val_accuracy: 0.3945 - val_loss: 0.2974\n",
            "Epoch 37/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4248 - loss: 0.2964 - val_accuracy: 0.3945 - val_loss: 0.2884\n",
            "Epoch 38/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4153 - loss: 0.2135 - val_accuracy: 0.3853 - val_loss: 0.2794\n",
            "Epoch 39/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4273 - loss: 0.2150 - val_accuracy: 0.3853 - val_loss: 0.2707\n",
            "Epoch 40/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4686 - loss: 0.3069 - val_accuracy: 0.3853 - val_loss: 0.2616\n",
            "Epoch 41/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4550 - loss: 0.2272 - val_accuracy: 0.3853 - val_loss: 0.2528\n",
            "Epoch 42/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4492 - loss: 0.1806 - val_accuracy: 0.3853 - val_loss: 0.2440\n",
            "Epoch 43/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4275 - loss: 0.2393 - val_accuracy: 0.3853 - val_loss: 0.2353\n",
            "Epoch 44/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4432 - loss: 0.1765 - val_accuracy: 0.3853 - val_loss: 0.2260\n",
            "Epoch 45/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4353 - loss: 0.1664 - val_accuracy: 0.3853 - val_loss: 0.2169\n",
            "Epoch 46/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4329 - loss: 0.1880 - val_accuracy: 0.3853 - val_loss: 0.2079\n",
            "Epoch 47/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4251 - loss: 0.0943 - val_accuracy: 0.3853 - val_loss: 0.1988\n",
            "Epoch 48/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4877 - loss: 0.1695 - val_accuracy: 0.3853 - val_loss: 0.1898\n",
            "Epoch 49/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4343 - loss: 0.1098 - val_accuracy: 0.3853 - val_loss: 0.1809\n",
            "Epoch 50/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4269 - loss: 0.0840 - val_accuracy: 0.3853 - val_loss: 0.1717\n",
            "Epoch 51/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4635 - loss: 0.1794 - val_accuracy: 0.3853 - val_loss: 0.1626\n",
            "Epoch 52/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4098 - loss: 0.0255 - val_accuracy: 0.3853 - val_loss: 0.1538\n",
            "Epoch 53/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3988 - loss: 0.0238 - val_accuracy: 0.3853 - val_loss: 0.1449\n",
            "Epoch 54/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4109 - loss: 0.0228 - val_accuracy: 0.3853 - val_loss: 0.1358\n",
            "Epoch 55/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4501 - loss: 0.0401 - val_accuracy: 0.3853 - val_loss: 0.1266\n",
            "Epoch 56/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4343 - loss: -0.0290 - val_accuracy: 0.3853 - val_loss: 0.1178\n",
            "Epoch 57/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4326 - loss: 0.0088 - val_accuracy: 0.3853 - val_loss: 0.1092\n",
            "Epoch 58/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4419 - loss: -0.0172 - val_accuracy: 0.3853 - val_loss: 0.1003\n",
            "Epoch 59/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4463 - loss: 0.0050 - val_accuracy: 0.3853 - val_loss: 0.0914\n",
            "Epoch 60/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3864 - loss: -0.0391 - val_accuracy: 0.3853 - val_loss: 0.0823\n",
            "Epoch 61/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4425 - loss: 0.0040 - val_accuracy: 0.3853 - val_loss: 0.0735\n",
            "Epoch 62/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4282 - loss: -0.0162 - val_accuracy: 0.3853 - val_loss: 0.0650\n",
            "Epoch 63/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4052 - loss: 0.0580 - val_accuracy: 0.3945 - val_loss: 0.0556\n",
            "Epoch 64/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4509 - loss: 0.0179 - val_accuracy: 0.3945 - val_loss: 0.0470\n",
            "Epoch 65/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3819 - loss: 0.0223 - val_accuracy: 0.3945 - val_loss: 0.0379\n",
            "Epoch 66/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4272 - loss: -0.0962 - val_accuracy: 0.3945 - val_loss: 0.0293\n",
            "Epoch 67/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: -0.0817 - val_accuracy: 0.3945 - val_loss: 0.0204\n",
            "Epoch 68/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4127 - loss: -0.1174 - val_accuracy: 0.3945 - val_loss: 0.0118\n",
            "Epoch 69/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4357 - loss: -0.0230 - val_accuracy: 0.3945 - val_loss: 0.0027\n",
            "Epoch 70/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4155 - loss: -0.1476 - val_accuracy: 0.3945 - val_loss: -0.0059\n",
            "Epoch 71/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4119 - loss: -0.1060 - val_accuracy: 0.3945 - val_loss: -0.0146\n",
            "Epoch 72/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4242 - loss: -0.2590 - val_accuracy: 0.3945 - val_loss: -0.0232\n",
            "Epoch 73/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4050 - loss: -0.0715 - val_accuracy: 0.3945 - val_loss: -0.0321\n",
            "Epoch 74/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4289 - loss: -0.1777 - val_accuracy: 0.3945 - val_loss: -0.0407\n",
            "Epoch 75/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4179 - loss: -0.2123 - val_accuracy: 0.3945 - val_loss: -0.0498\n",
            "Epoch 76/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4284 - loss: -0.2631 - val_accuracy: 0.3853 - val_loss: -0.0587\n",
            "Epoch 77/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4557 - loss: -0.2251 - val_accuracy: 0.3853 - val_loss: -0.0674\n",
            "Epoch 78/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4439 - loss: -0.3167 - val_accuracy: 0.3853 - val_loss: -0.0759\n",
            "Epoch 79/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4345 - loss: -0.1139 - val_accuracy: 0.3853 - val_loss: -0.0841\n",
            "Epoch 80/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4144 - loss: -0.2257 - val_accuracy: 0.3853 - val_loss: -0.0927\n",
            "Epoch 81/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4204 - loss: -0.1409 - val_accuracy: 0.3853 - val_loss: -0.1013\n",
            "Epoch 82/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4691 - loss: -0.2628 - val_accuracy: 0.3853 - val_loss: -0.1104\n",
            "Epoch 83/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4645 - loss: -0.3155 - val_accuracy: 0.3853 - val_loss: -0.1190\n",
            "Epoch 84/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4285 - loss: -0.2556 - val_accuracy: 0.3853 - val_loss: -0.1277\n",
            "Epoch 85/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4100 - loss: -0.2919 - val_accuracy: 0.3853 - val_loss: -0.1367\n",
            "Epoch 86/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4499 - loss: -0.2728 - val_accuracy: 0.3853 - val_loss: -0.1461\n",
            "Epoch 87/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4245 - loss: -0.3797 - val_accuracy: 0.3853 - val_loss: -0.1552\n",
            "Epoch 88/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4102 - loss: -0.4193 - val_accuracy: 0.3853 - val_loss: -0.1640\n",
            "Epoch 89/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4428 - loss: -0.1123 - val_accuracy: 0.3853 - val_loss: -0.1727\n",
            "Epoch 90/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4433 - loss: -0.5035 - val_accuracy: 0.3853 - val_loss: -0.1817\n",
            "Epoch 91/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4657 - loss: -0.1942 - val_accuracy: 0.3853 - val_loss: -0.1906\n",
            "Epoch 92/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4224 - loss: -0.2532 - val_accuracy: 0.3853 - val_loss: -0.1998\n",
            "Epoch 93/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4205 - loss: -0.3863 - val_accuracy: 0.3853 - val_loss: -0.2086\n",
            "Epoch 94/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4468 - loss: -0.3380 - val_accuracy: 0.3853 - val_loss: -0.2175\n",
            "Epoch 95/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4455 - loss: -0.4170 - val_accuracy: 0.3853 - val_loss: -0.2271\n",
            "Epoch 96/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4125 - loss: -0.4198 - val_accuracy: 0.3853 - val_loss: -0.2364\n",
            "Epoch 97/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4240 - loss: -0.4053 - val_accuracy: 0.3853 - val_loss: -0.2465\n",
            "Epoch 98/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4392 - loss: -0.6650 - val_accuracy: 0.3853 - val_loss: -0.2557\n",
            "Epoch 99/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4624 - loss: -0.1829 - val_accuracy: 0.3853 - val_loss: -0.2647\n",
            "Epoch 100/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3895 - loss: -0.4183 - val_accuracy: 0.3853 - val_loss: -0.2735\n",
            "Epoch 101/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4524 - loss: -0.3846 - val_accuracy: 0.3853 - val_loss: -0.2825\n",
            "Epoch 102/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4684 - loss: -0.4168 - val_accuracy: 0.3853 - val_loss: -0.2927\n",
            "Epoch 103/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4490 - loss: -0.4841 - val_accuracy: 0.3853 - val_loss: -0.3017\n",
            "Epoch 104/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4225 - loss: -0.4389 - val_accuracy: 0.3853 - val_loss: -0.3106\n",
            "Epoch 105/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4873 - loss: -0.6387 - val_accuracy: 0.3853 - val_loss: -0.3195\n",
            "Epoch 106/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4525 - loss: -0.4957 - val_accuracy: 0.3853 - val_loss: -0.3289\n",
            "Epoch 107/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4433 - loss: -0.4315 - val_accuracy: 0.3853 - val_loss: -0.3379\n",
            "Epoch 108/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4186 - loss: -0.8045 - val_accuracy: 0.3853 - val_loss: -0.3470\n",
            "Epoch 109/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4183 - loss: -0.6730 - val_accuracy: 0.3853 - val_loss: -0.3563\n",
            "Epoch 110/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4300 - loss: -0.1881 - val_accuracy: 0.3853 - val_loss: -0.3658\n",
            "Epoch 111/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4005 - loss: -0.6074 - val_accuracy: 0.3853 - val_loss: -0.3756\n",
            "Epoch 112/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4484 - loss: -0.5947 - val_accuracy: 0.3761 - val_loss: -0.3846\n",
            "Epoch 113/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4127 - loss: -0.5472 - val_accuracy: 0.3761 - val_loss: -0.3944\n",
            "Epoch 114/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4524 - loss: -0.5338 - val_accuracy: 0.3761 - val_loss: -0.4034\n",
            "Epoch 115/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4334 - loss: -0.5423 - val_accuracy: 0.3761 - val_loss: -0.4121\n",
            "Epoch 116/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4461 - loss: -0.5817 - val_accuracy: 0.3761 - val_loss: -0.4217\n",
            "Epoch 117/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4380 - loss: -0.3879 - val_accuracy: 0.3761 - val_loss: -0.4312\n",
            "Epoch 118/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4231 - loss: -0.6976 - val_accuracy: 0.3761 - val_loss: -0.4409\n",
            "Epoch 119/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4032 - loss: -0.8293 - val_accuracy: 0.3761 - val_loss: -0.4502\n",
            "Epoch 120/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4041 - loss: -0.7048 - val_accuracy: 0.3761 - val_loss: -0.4592\n",
            "Epoch 121/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4574 - loss: -0.7859 - val_accuracy: 0.3761 - val_loss: -0.4689\n",
            "Epoch 122/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4563 - loss: -0.5383 - val_accuracy: 0.3761 - val_loss: -0.4782\n",
            "Epoch 123/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4271 - loss: -0.7692 - val_accuracy: 0.3761 - val_loss: -0.4873\n",
            "Epoch 124/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4387 - loss: -0.6412 - val_accuracy: 0.3761 - val_loss: -0.4971\n",
            "Epoch 125/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4198 - loss: -1.0276 - val_accuracy: 0.3761 - val_loss: -0.5056\n",
            "Epoch 126/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4435 - loss: -0.6280 - val_accuracy: 0.3761 - val_loss: -0.5150\n",
            "Epoch 127/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4663 - loss: -0.6361 - val_accuracy: 0.3761 - val_loss: -0.5250\n",
            "Epoch 128/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4549 - loss: -0.6715 - val_accuracy: 0.3761 - val_loss: -0.5343\n",
            "Epoch 129/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3990 - loss: -0.8073 - val_accuracy: 0.3761 - val_loss: -0.5437\n",
            "Epoch 130/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4404 - loss: -1.1010 - val_accuracy: 0.3761 - val_loss: -0.5535\n",
            "Epoch 131/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4327 - loss: -0.7659 - val_accuracy: 0.3761 - val_loss: -0.5633\n",
            "Epoch 132/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4183 - loss: -0.8333 - val_accuracy: 0.3761 - val_loss: -0.5735\n",
            "Epoch 133/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4045 - loss: -0.7861 - val_accuracy: 0.3761 - val_loss: -0.5830\n",
            "Epoch 134/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4527 - loss: -1.0168 - val_accuracy: 0.3761 - val_loss: -0.5926\n",
            "Epoch 135/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4391 - loss: -0.6405 - val_accuracy: 0.3761 - val_loss: -0.6033\n",
            "Epoch 136/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4377 - loss: -1.1215 - val_accuracy: 0.3761 - val_loss: -0.6136\n",
            "Epoch 137/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4569 - loss: -0.8453 - val_accuracy: 0.3761 - val_loss: -0.6235\n",
            "Epoch 138/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4373 - loss: -1.0518 - val_accuracy: 0.3761 - val_loss: -0.6328\n",
            "Epoch 139/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4414 - loss: -0.9483 - val_accuracy: 0.3761 - val_loss: -0.6421\n",
            "Epoch 140/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4403 - loss: -1.2554 - val_accuracy: 0.3761 - val_loss: -0.6520\n",
            "Epoch 141/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4191 - loss: -0.9264 - val_accuracy: 0.3761 - val_loss: -0.6622\n",
            "Epoch 142/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4450 - loss: -1.0633 - val_accuracy: 0.3761 - val_loss: -0.6719\n",
            "Epoch 143/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4559 - loss: -0.9683 - val_accuracy: 0.3761 - val_loss: -0.6816\n",
            "Epoch 144/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4384 - loss: -0.9853 - val_accuracy: 0.3670 - val_loss: -0.6918\n",
            "Epoch 145/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4678 - loss: -0.8448 - val_accuracy: 0.3670 - val_loss: -0.7022\n",
            "Epoch 146/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4355 - loss: -0.9669 - val_accuracy: 0.3670 - val_loss: -0.7116\n",
            "Epoch 147/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3997 - loss: -0.8898 - val_accuracy: 0.3670 - val_loss: -0.7212\n",
            "Epoch 148/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4618 - loss: -0.8543 - val_accuracy: 0.3670 - val_loss: -0.7317\n",
            "Epoch 149/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: -0.8852 - val_accuracy: 0.3670 - val_loss: -0.7415\n",
            "Epoch 150/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4552 - loss: -0.9757 - val_accuracy: 0.3670 - val_loss: -0.7513\n",
            "Epoch 151/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3956 - loss: -1.1579 - val_accuracy: 0.3670 - val_loss: -0.7618\n",
            "Epoch 152/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4379 - loss: -0.9499 - val_accuracy: 0.3670 - val_loss: -0.7719\n",
            "Epoch 153/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4527 - loss: -1.2818 - val_accuracy: 0.3670 - val_loss: -0.7821\n",
            "Epoch 154/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3932 - loss: -0.9327 - val_accuracy: 0.3670 - val_loss: -0.7924\n",
            "Epoch 155/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4273 - loss: -0.7388 - val_accuracy: 0.3670 - val_loss: -0.8023\n",
            "Epoch 156/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4315 - loss: -0.8857 - val_accuracy: 0.3670 - val_loss: -0.8126\n",
            "Epoch 157/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4017 - loss: -1.4459 - val_accuracy: 0.3670 - val_loss: -0.8230\n",
            "Epoch 158/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4642 - loss: -1.0844 - val_accuracy: 0.3670 - val_loss: -0.8336\n",
            "Epoch 159/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: -1.0303 - val_accuracy: 0.3670 - val_loss: -0.8441\n",
            "Epoch 160/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4256 - loss: -1.2363 - val_accuracy: 0.3670 - val_loss: -0.8541\n",
            "Epoch 161/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4379 - loss: -1.1324 - val_accuracy: 0.3670 - val_loss: -0.8641\n",
            "Epoch 162/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4491 - loss: -1.1893 - val_accuracy: 0.3578 - val_loss: -0.8742\n",
            "Epoch 163/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4342 - loss: -1.1492 - val_accuracy: 0.3578 - val_loss: -0.8838\n",
            "Epoch 164/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4280 - loss: -1.0740 - val_accuracy: 0.3578 - val_loss: -0.8946\n",
            "Epoch 165/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4700 - loss: -1.1531 - val_accuracy: 0.3578 - val_loss: -0.9048\n",
            "Epoch 166/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3796 - loss: -1.5692 - val_accuracy: 0.3578 - val_loss: -0.9150\n",
            "Epoch 167/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4344 - loss: -1.3303 - val_accuracy: 0.3578 - val_loss: -0.9246\n",
            "Epoch 168/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4395 - loss: -1.2189 - val_accuracy: 0.3578 - val_loss: -0.9359\n",
            "Epoch 169/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4499 - loss: -1.0792 - val_accuracy: 0.3578 - val_loss: -0.9453\n",
            "Epoch 170/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4310 - loss: -1.0744 - val_accuracy: 0.3578 - val_loss: -0.9560\n",
            "Epoch 171/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4199 - loss: -1.7672 - val_accuracy: 0.3578 - val_loss: -0.9662\n",
            "Epoch 172/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4230 - loss: -1.4563 - val_accuracy: 0.3578 - val_loss: -0.9770\n",
            "Epoch 173/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4201 - loss: -1.5715 - val_accuracy: 0.3578 - val_loss: -0.9880\n",
            "Epoch 174/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4526 - loss: -1.2145 - val_accuracy: 0.3578 - val_loss: -0.9984\n",
            "Epoch 175/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4301 - loss: -1.7992 - val_accuracy: 0.3578 - val_loss: -1.0082\n",
            "Epoch 176/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4352 - loss: -1.0489 - val_accuracy: 0.3578 - val_loss: -1.0192\n",
            "Epoch 177/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4234 - loss: -1.7442 - val_accuracy: 0.3578 - val_loss: -1.0310\n",
            "Epoch 178/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4293 - loss: -1.5846 - val_accuracy: 0.3578 - val_loss: -1.0413\n",
            "Epoch 179/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4365 - loss: -1.4700 - val_accuracy: 0.3578 - val_loss: -1.0526\n",
            "Epoch 180/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4745 - loss: -1.4153 - val_accuracy: 0.3578 - val_loss: -1.0635\n",
            "Epoch 181/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4529 - loss: -1.4967 - val_accuracy: 0.3578 - val_loss: -1.0741\n",
            "Epoch 182/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4467 - loss: -1.7512 - val_accuracy: 0.3578 - val_loss: -1.0847\n",
            "Epoch 183/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4152 - loss: -1.4827 - val_accuracy: 0.3578 - val_loss: -1.0954\n",
            "Epoch 184/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4070 - loss: -1.6957 - val_accuracy: 0.3578 - val_loss: -1.1066\n",
            "Epoch 185/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3983 - loss: -2.0012 - val_accuracy: 0.3578 - val_loss: -1.1177\n",
            "Epoch 186/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4145 - loss: -0.9993 - val_accuracy: 0.3578 - val_loss: -1.1285\n",
            "Epoch 187/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4549 - loss: -1.9851 - val_accuracy: 0.3578 - val_loss: -1.1406\n",
            "Epoch 188/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4419 - loss: -1.2181 - val_accuracy: 0.3578 - val_loss: -1.1522\n",
            "Epoch 189/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4186 - loss: -1.2739 - val_accuracy: 0.3578 - val_loss: -1.1630\n",
            "Epoch 190/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4640 - loss: -1.4146 - val_accuracy: 0.3578 - val_loss: -1.1740\n",
            "Epoch 191/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4857 - loss: -1.5674 - val_accuracy: 0.3578 - val_loss: -1.1858\n",
            "Epoch 192/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4409 - loss: -1.4942 - val_accuracy: 0.3578 - val_loss: -1.1969\n",
            "Epoch 193/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4151 - loss: -2.0340 - val_accuracy: 0.3578 - val_loss: -1.2090\n",
            "Epoch 194/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4884 - loss: -1.5979 - val_accuracy: 0.3578 - val_loss: -1.2201\n",
            "Epoch 195/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4032 - loss: -1.9130 - val_accuracy: 0.3578 - val_loss: -1.2317\n",
            "Epoch 196/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4416 - loss: -1.2843 - val_accuracy: 0.3578 - val_loss: -1.2426\n",
            "Epoch 197/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3871 - loss: -2.0180 - val_accuracy: 0.3578 - val_loss: -1.2539\n",
            "Epoch 198/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4224 - loss: -1.9298 - val_accuracy: 0.3578 - val_loss: -1.2653\n",
            "Epoch 199/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4648 - loss: -1.3567 - val_accuracy: 0.3578 - val_loss: -1.2774\n",
            "Epoch 200/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4141 - loss: -1.8877 - val_accuracy: 0.3578 - val_loss: -1.2896\n",
            "Epoch 201/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4862 - loss: -1.9275 - val_accuracy: 0.3578 - val_loss: -1.3011\n",
            "Epoch 202/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4597 - loss: -2.2618 - val_accuracy: 0.3578 - val_loss: -1.3130\n",
            "Epoch 203/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4293 - loss: -1.5601 - val_accuracy: 0.3578 - val_loss: -1.3240\n",
            "Epoch 204/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4179 - loss: -1.6600 - val_accuracy: 0.3578 - val_loss: -1.3358\n",
            "Epoch 205/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4342 - loss: -2.0460 - val_accuracy: 0.3578 - val_loss: -1.3478\n",
            "Epoch 206/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4313 - loss: -2.1517 - val_accuracy: 0.3578 - val_loss: -1.3590\n",
            "Epoch 207/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4609 - loss: -2.2748 - val_accuracy: 0.3578 - val_loss: -1.3702\n",
            "Epoch 208/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4680 - loss: -1.8698 - val_accuracy: 0.3578 - val_loss: -1.3818\n",
            "Epoch 209/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4357 - loss: -2.0232 - val_accuracy: 0.3578 - val_loss: -1.3939\n",
            "Epoch 210/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4403 - loss: -1.8124 - val_accuracy: 0.3578 - val_loss: -1.4063\n",
            "Epoch 211/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4268 - loss: -1.6777 - val_accuracy: 0.3578 - val_loss: -1.4186\n",
            "Epoch 212/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4452 - loss: -1.9114 - val_accuracy: 0.3578 - val_loss: -1.4304\n",
            "Epoch 213/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4423 - loss: -2.0229 - val_accuracy: 0.3578 - val_loss: -1.4424\n",
            "Epoch 214/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4349 - loss: -2.0533 - val_accuracy: 0.3578 - val_loss: -1.4539\n",
            "Epoch 215/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4433 - loss: -1.8449 - val_accuracy: 0.3578 - val_loss: -1.4658\n",
            "Epoch 216/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4320 - loss: -2.0747 - val_accuracy: 0.3578 - val_loss: -1.4774\n",
            "Epoch 217/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4252 - loss: -2.0504 - val_accuracy: 0.3578 - val_loss: -1.4900\n",
            "Epoch 218/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4443 - loss: -1.8147 - val_accuracy: 0.3578 - val_loss: -1.5037\n",
            "Epoch 219/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4216 - loss: -1.7615 - val_accuracy: 0.3578 - val_loss: -1.5162\n",
            "Epoch 220/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4298 - loss: -2.1394 - val_accuracy: 0.3578 - val_loss: -1.5290\n",
            "Epoch 221/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4361 - loss: -2.6347 - val_accuracy: 0.3578 - val_loss: -1.5418\n",
            "Epoch 222/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4762 - loss: -2.2935 - val_accuracy: 0.3578 - val_loss: -1.5541\n",
            "Epoch 223/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4102 - loss: -2.4387 - val_accuracy: 0.3578 - val_loss: -1.5666\n",
            "Epoch 224/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4254 - loss: -2.1555 - val_accuracy: 0.3578 - val_loss: -1.5794\n",
            "Epoch 225/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4385 - loss: -2.2337 - val_accuracy: 0.3578 - val_loss: -1.5925\n",
            "Epoch 226/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4143 - loss: -2.0407 - val_accuracy: 0.3578 - val_loss: -1.6047\n",
            "Epoch 227/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4581 - loss: -2.0472 - val_accuracy: 0.3578 - val_loss: -1.6174\n",
            "Epoch 228/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4865 - loss: -2.0422 - val_accuracy: 0.3578 - val_loss: -1.6308\n",
            "Epoch 229/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4685 - loss: -1.9303 - val_accuracy: 0.3578 - val_loss: -1.6421\n",
            "Epoch 230/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4479 - loss: -1.8120 - val_accuracy: 0.3578 - val_loss: -1.6551\n",
            "Epoch 231/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4470 - loss: -1.4008 - val_accuracy: 0.3578 - val_loss: -1.6684\n",
            "Epoch 232/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4424 - loss: -2.0768 - val_accuracy: 0.3578 - val_loss: -1.6811\n",
            "Epoch 233/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4263 - loss: -2.3080 - val_accuracy: 0.3578 - val_loss: -1.6945\n",
            "Epoch 234/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4458 - loss: -2.5936 - val_accuracy: 0.3578 - val_loss: -1.7078\n",
            "Epoch 235/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4200 - loss: -3.1985 - val_accuracy: 0.3578 - val_loss: -1.7212\n",
            "Epoch 236/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4610 - loss: -2.2262 - val_accuracy: 0.3578 - val_loss: -1.7331\n",
            "Epoch 237/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4428 - loss: -2.2632 - val_accuracy: 0.3578 - val_loss: -1.7467\n",
            "Epoch 238/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4369 - loss: -2.7924 - val_accuracy: 0.3578 - val_loss: -1.7593\n",
            "Epoch 239/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4291 - loss: -3.0205 - val_accuracy: 0.3578 - val_loss: -1.7722\n",
            "Epoch 240/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4495 - loss: -2.0803 - val_accuracy: 0.3578 - val_loss: -1.7854\n",
            "Epoch 241/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4348 - loss: -2.4355 - val_accuracy: 0.3578 - val_loss: -1.7987\n",
            "Epoch 242/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4315 - loss: -2.0845 - val_accuracy: 0.3578 - val_loss: -1.8117\n",
            "Epoch 243/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4614 - loss: -1.8456 - val_accuracy: 0.3578 - val_loss: -1.8259\n",
            "Epoch 244/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4280 - loss: -3.0632 - val_accuracy: 0.3578 - val_loss: -1.8392\n",
            "Epoch 245/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4217 - loss: -2.2201 - val_accuracy: 0.3578 - val_loss: -1.8529\n",
            "Epoch 246/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4101 - loss: -2.9987 - val_accuracy: 0.3578 - val_loss: -1.8653\n",
            "Epoch 247/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4234 - loss: -2.7466 - val_accuracy: 0.3578 - val_loss: -1.8787\n",
            "Epoch 248/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4042 - loss: -2.8878 - val_accuracy: 0.3578 - val_loss: -1.8910\n",
            "Epoch 249/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4253 - loss: -1.9450 - val_accuracy: 0.3578 - val_loss: -1.9053\n",
            "Epoch 250/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4674 - loss: -2.3211 - val_accuracy: 0.3578 - val_loss: -1.9187\n",
            "Epoch 251/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4212 - loss: -2.2753 - val_accuracy: 0.3486 - val_loss: -1.9331\n",
            "Epoch 252/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4199 - loss: -2.8653 - val_accuracy: 0.3486 - val_loss: -1.9470\n",
            "Epoch 253/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3767 - loss: -3.8780 - val_accuracy: 0.3486 - val_loss: -1.9613\n",
            "Epoch 254/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4523 - loss: -2.1436 - val_accuracy: 0.3486 - val_loss: -1.9759\n",
            "Epoch 255/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4570 - loss: -2.6035 - val_accuracy: 0.3486 - val_loss: -1.9904\n",
            "Epoch 256/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4414 - loss: -2.6727 - val_accuracy: 0.3486 - val_loss: -2.0052\n",
            "Epoch 257/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4407 - loss: -2.7560 - val_accuracy: 0.3486 - val_loss: -2.0195\n",
            "Epoch 258/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4560 - loss: -2.1710 - val_accuracy: 0.3486 - val_loss: -2.0334\n",
            "Epoch 259/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4721 - loss: -2.4037 - val_accuracy: 0.3486 - val_loss: -2.0478\n",
            "Epoch 260/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4346 - loss: -3.0856 - val_accuracy: 0.3486 - val_loss: -2.0616\n",
            "Epoch 261/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4567 - loss: -2.2887 - val_accuracy: 0.3486 - val_loss: -2.0761\n",
            "Epoch 262/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4314 - loss: -2.2555 - val_accuracy: 0.3486 - val_loss: -2.0902\n",
            "Epoch 263/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4236 - loss: -3.2270 - val_accuracy: 0.3486 - val_loss: -2.1038\n",
            "Epoch 264/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4798 - loss: -3.0981 - val_accuracy: 0.3486 - val_loss: -2.1190\n",
            "Epoch 265/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4563 - loss: -2.3591 - val_accuracy: 0.3486 - val_loss: -2.1332\n",
            "Epoch 266/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4406 - loss: -2.8392 - val_accuracy: 0.3486 - val_loss: -2.1476\n",
            "Epoch 267/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4313 - loss: -2.6574 - val_accuracy: 0.3486 - val_loss: -2.1627\n",
            "Epoch 268/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4869 - loss: -1.9453 - val_accuracy: 0.3486 - val_loss: -2.1774\n",
            "Epoch 269/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4024 - loss: -2.4913 - val_accuracy: 0.3486 - val_loss: -2.1934\n",
            "Epoch 270/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4220 - loss: -2.9705 - val_accuracy: 0.3486 - val_loss: -2.2085\n",
            "Epoch 271/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4584 - loss: -2.2851 - val_accuracy: 0.3486 - val_loss: -2.2245\n",
            "Epoch 272/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4465 - loss: -3.4689 - val_accuracy: 0.3486 - val_loss: -2.2396\n",
            "Epoch 273/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4016 - loss: -3.2126 - val_accuracy: 0.3486 - val_loss: -2.2542\n",
            "Epoch 274/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4399 - loss: -2.8388 - val_accuracy: 0.3486 - val_loss: -2.2696\n",
            "Epoch 275/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3974 - loss: -2.8380 - val_accuracy: 0.3486 - val_loss: -2.2835\n",
            "Epoch 276/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4562 - loss: -2.7402 - val_accuracy: 0.3486 - val_loss: -2.2975\n",
            "Epoch 277/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4377 - loss: -2.9512 - val_accuracy: 0.3486 - val_loss: -2.3119\n",
            "Epoch 278/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4202 - loss: -3.8560 - val_accuracy: 0.3486 - val_loss: -2.3275\n",
            "Epoch 279/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4204 - loss: -2.2330 - val_accuracy: 0.3486 - val_loss: -2.3427\n",
            "Epoch 280/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4300 - loss: -3.1244 - val_accuracy: 0.3486 - val_loss: -2.3577\n",
            "Epoch 281/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4435 - loss: -2.5958 - val_accuracy: 0.3486 - val_loss: -2.3728\n",
            "Epoch 282/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4131 - loss: -3.5920 - val_accuracy: 0.3486 - val_loss: -2.3881\n",
            "Epoch 283/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3906 - loss: -2.9673 - val_accuracy: 0.3486 - val_loss: -2.4037\n",
            "Epoch 284/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4268 - loss: -3.7287 - val_accuracy: 0.3486 - val_loss: -2.4189\n",
            "Epoch 285/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4389 - loss: -3.8714 - val_accuracy: 0.3486 - val_loss: -2.4354\n",
            "Epoch 286/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4242 - loss: -2.9023 - val_accuracy: 0.3486 - val_loss: -2.4509\n",
            "Epoch 287/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4477 - loss: -3.6825 - val_accuracy: 0.3486 - val_loss: -2.4668\n",
            "Epoch 288/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4454 - loss: -4.1209 - val_accuracy: 0.3486 - val_loss: -2.4831\n",
            "Epoch 289/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4296 - loss: -3.3539 - val_accuracy: 0.3486 - val_loss: -2.4992\n",
            "Epoch 290/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4382 - loss: -3.3654 - val_accuracy: 0.3486 - val_loss: -2.5147\n",
            "Epoch 291/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4236 - loss: -2.7946 - val_accuracy: 0.3486 - val_loss: -2.5302\n",
            "Epoch 292/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4372 - loss: -3.7863 - val_accuracy: 0.3486 - val_loss: -2.5458\n",
            "Epoch 293/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4576 - loss: -3.3506 - val_accuracy: 0.3486 - val_loss: -2.5615\n",
            "Epoch 294/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4743 - loss: -3.2646 - val_accuracy: 0.3486 - val_loss: -2.5777\n",
            "Epoch 295/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4362 - loss: -3.7439 - val_accuracy: 0.3486 - val_loss: -2.5932\n",
            "Epoch 296/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4667 - loss: -3.8502 - val_accuracy: 0.3486 - val_loss: -2.6095\n",
            "Epoch 297/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4417 - loss: -3.5084 - val_accuracy: 0.3486 - val_loss: -2.6260\n",
            "Epoch 298/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4466 - loss: -2.6288 - val_accuracy: 0.3486 - val_loss: -2.6417\n",
            "Epoch 299/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4041 - loss: -4.8793 - val_accuracy: 0.3486 - val_loss: -2.6579\n",
            "Epoch 300/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4720 - loss: -2.9775 - val_accuracy: 0.3486 - val_loss: -2.6752\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3322 - loss: -3.1051\n",
            "Test Accuracy: 0.3486\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Confusion Matrix:\n",
            " [[ 0 29  0]\n",
            " [ 1 38  0]\n",
            " [ 0 41  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.35      0.97      0.52        39\n",
            "           2       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.35       109\n",
            "   macro avg       0.12      0.32      0.17       109\n",
            "weighted avg       0.13      0.35      0.18       109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}