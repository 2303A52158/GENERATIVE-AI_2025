{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVUHfgSn0t66pU8cqgE7/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52158/GENERATIVE-AI_2025/blob/main/Generative_AI_2303A52158_Ass_6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Design a multilayer ANN architecture according to the requirements shown below. Train, test, save (.h5) and deploy the model to predict the housing price using Keras deep\n",
        "learning library**\n",
        "\n",
        "**2. (1 ponto) Calculate training and testing error metrics.**\n",
        "\n",
        "**3. (1 ponto) Build the application by loading the saved ANN model.**\n",
        "\n",
        "                            Tabela 1: ANN Architecture\n",
        "                      Layer       Neurons Activation-Function\n",
        "                  Hidden Layer-1    18           swish\n",
        "                  Hidden Layer-2    26           swish\n",
        "                  Hidden Layer-3    20           swish\n",
        "                  Hidden Layer-4    15           swish\n",
        "\n",
        "                            Tabela 2: Training Parameters\n",
        "      loss-function epochs batch-size error-metric Optimizer\n",
        "          MSE         200     64          RMSE      rmsprop"
      ],
      "metadata": {
        "id": "ct_ZaBbc5lXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "data = pd.read_csv('/content/Housing.csv')\n",
        "categorical_features = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_data = encoder.fit_transform(data[categorical_features])\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_features))\n",
        "\n",
        "numerical_features = data.drop(columns=categorical_features)\n",
        "X = pd.concat([numerical_features.drop('price', axis=1), encoded_df], axis=1)\n",
        "y = data['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(18, activation='swish', input_shape=(X_train.shape[1],)),\n",
        "    Dense(26, activation='swish'),\n",
        "    Dense(20, activation='swish'),\n",
        "    Dense(15, activation='swish'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=RMSprop(), metrics=['mae'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "model.save('housing_price_model.h5')\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "train_rmae = np.sqrt(mean_absolute_error(y_train, y_train_pred))\n",
        "test_rmae = np.sqrt(mean_absolute_error(y_test, y_test_pred))\n",
        "\n",
        "print(f\"Training MSE: {train_mse:.4f}\")\n",
        "print(f\"Testing MSE: {test_mse:.4f}\")\n",
        "print(f\"Training RMAE: {train_rmae:.4f}\")\n",
        "print(f\"Testing RMAE: {test_rmae:.4f}\")\n",
        "\n",
        "loaded_model = load_model('housing_price_model.h5')\n",
        "\n",
        "def predict_housing_price(features):\n",
        "    user_input_df = pd.DataFrame([features[:len(numerical_features.columns) - 1]],\n",
        "                                 columns=numerical_features.columns[1:])\n",
        "\n",
        "    categorical_input_df = pd.DataFrame([features[len(numerical_features.columns) - 1:]],\n",
        "                                        columns=categorical_features).astype(str)\n",
        "\n",
        "    encoded_user_input = encoder.transform(categorical_input_df)\n",
        "    encoded_user_input_df = pd.DataFrame(encoded_user_input, columns=encoder.get_feature_names_out(categorical_features))\n",
        "\n",
        "    final_input_df = pd.concat([user_input_df, encoded_user_input_df], axis=1)\n",
        "\n",
        "    scaled_input = scaler.transform(final_input_df)\n",
        "\n",
        "    prediction = loaded_model.predict(scaled_input)\n",
        "    return prediction[0][0]\n",
        "\n",
        "user_input = [8000, 3, 2, 2, 1, 1, 'yes', 'no', 'no', 'yes', 'no', 'furnished']\n",
        "predicted_price = predict_housing_price(user_input)\n",
        "print(f\"Predicted Housing Price: {predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ6P6zn4-TFG",
        "outputId": "02ad74f8-fead-45bc-9ede-250c052e1ff8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - loss: 25491144704000.0000 - mae: 4741285.5000 - val_loss: 30129992499200.0000 - val_mae: 5007536.5000\n",
            "Epoch 2/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24266112237568.0000 - mae: 4635167.5000 - val_loss: 30129988304896.0000 - val_mae: 5007536.0000\n",
            "Epoch 3/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 25263746318336.0000 - mae: 4700828.0000 - val_loss: 30129988304896.0000 - val_mae: 5007536.0000\n",
            "Epoch 4/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24991376605184.0000 - mae: 4670789.5000 - val_loss: 30129986207744.0000 - val_mae: 5007535.5000\n",
            "Epoch 5/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24708319805440.0000 - mae: 4677204.0000 - val_loss: 30129982013440.0000 - val_mae: 5007535.0000\n",
            "Epoch 6/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25088124518400.0000 - mae: 4688573.0000 - val_loss: 30129973624832.0000 - val_mae: 5007535.0000\n",
            "Epoch 7/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24579319791616.0000 - mae: 4661129.5000 - val_loss: 30129963139072.0000 - val_mae: 5007534.0000\n",
            "Epoch 8/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25818036174848.0000 - mae: 4780877.5000 - val_loss: 30129952653312.0000 - val_mae: 5007533.0000\n",
            "Epoch 9/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24928132792320.0000 - mae: 4683600.0000 - val_loss: 30129940070400.0000 - val_mae: 5007531.5000\n",
            "Epoch 10/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24864782024704.0000 - mae: 4678413.0000 - val_loss: 30129919098880.0000 - val_mae: 5007530.5000\n",
            "Epoch 11/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26434072477696.0000 - mae: 4796970.5000 - val_loss: 30129900224512.0000 - val_mae: 5007528.0000\n",
            "Epoch 12/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25138531663872.0000 - mae: 4699806.0000 - val_loss: 30129870864384.0000 - val_mae: 5007525.5000\n",
            "Epoch 13/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26828699860992.0000 - mae: 4825691.0000 - val_loss: 30129835212800.0000 - val_mae: 5007522.5000\n",
            "Epoch 14/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25375279153152.0000 - mae: 4728927.0000 - val_loss: 30129797464064.0000 - val_mae: 5007519.5000\n",
            "Epoch 15/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25021084860416.0000 - mae: 4693828.5000 - val_loss: 30129749229568.0000 - val_mae: 5007515.5000\n",
            "Epoch 16/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25982232690688.0000 - mae: 4780878.0000 - val_loss: 30129692606464.0000 - val_mae: 5007510.5000\n",
            "Epoch 17/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25071762538496.0000 - mae: 4669085.0000 - val_loss: 30129629691904.0000 - val_mae: 5007505.0000\n",
            "Epoch 18/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23956937506816.0000 - mae: 4601838.5000 - val_loss: 30129550000128.0000 - val_mae: 5007498.5000\n",
            "Epoch 19/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25423450734592.0000 - mae: 4736667.0000 - val_loss: 30129466114048.0000 - val_mae: 5007491.5000\n",
            "Epoch 20/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26175659311104.0000 - mae: 4788056.5000 - val_loss: 30129367547904.0000 - val_mae: 5007483.5000\n",
            "Epoch 21/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25922887483392.0000 - mae: 4777836.5000 - val_loss: 30129260593152.0000 - val_mae: 5007473.5000\n",
            "Epoch 22/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25631616139264.0000 - mae: 4748334.0000 - val_loss: 30129124278272.0000 - val_mae: 5007463.0000\n",
            "Epoch 23/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25116981329920.0000 - mae: 4710018.5000 - val_loss: 30128979574784.0000 - val_mae: 5007450.5000\n",
            "Epoch 24/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25681872289792.0000 - mae: 4766565.5000 - val_loss: 30128813899776.0000 - val_mae: 5007436.5000\n",
            "Epoch 25/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26978147106816.0000 - mae: 4837892.5000 - val_loss: 30128631447552.0000 - val_mae: 5007421.0000\n",
            "Epoch 26/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24208803364864.0000 - mae: 4603504.0000 - val_loss: 30128419635200.0000 - val_mae: 5007403.5000\n",
            "Epoch 27/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25848824463360.0000 - mae: 4758721.0000 - val_loss: 30128188948480.0000 - val_mae: 5007384.0000\n",
            "Epoch 28/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24170343694336.0000 - mae: 4601422.0000 - val_loss: 30127924707328.0000 - val_mae: 5007362.5000\n",
            "Epoch 29/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25666384822272.0000 - mae: 4750543.0000 - val_loss: 30127645786112.0000 - val_mae: 5007339.5000\n",
            "Epoch 30/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25465639141376.0000 - mae: 4726760.0000 - val_loss: 30127333310464.0000 - val_mae: 5007313.5000\n",
            "Epoch 31/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25444621484032.0000 - mae: 4722128.5000 - val_loss: 30126989377536.0000 - val_mae: 5007285.0000\n",
            "Epoch 32/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25031759364096.0000 - mae: 4694082.5000 - val_loss: 30126599307264.0000 - val_mae: 5007253.0000\n",
            "Epoch 33/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25120502448128.0000 - mae: 4695816.0000 - val_loss: 30126177779712.0000 - val_mae: 5007218.0000\n",
            "Epoch 34/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26594647212032.0000 - mae: 4816210.0000 - val_loss: 30125718503424.0000 - val_mae: 5007180.5000\n",
            "Epoch 35/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24453033492480.0000 - mae: 4631646.5000 - val_loss: 30125213089792.0000 - val_mae: 5007138.5000\n",
            "Epoch 36/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25116744351744.0000 - mae: 4676188.5000 - val_loss: 30124663635968.0000 - val_mae: 5007093.5000\n",
            "Epoch 37/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25219158769664.0000 - mae: 4700979.0000 - val_loss: 30124063850496.0000 - val_mae: 5007044.5000\n",
            "Epoch 38/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25357455458304.0000 - mae: 4712831.5000 - val_loss: 30123413733376.0000 - val_mae: 5006991.5000\n",
            "Epoch 39/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25840219848704.0000 - mae: 4758271.5000 - val_loss: 30122706993152.0000 - val_mae: 5006933.5000\n",
            "Epoch 40/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24218970357760.0000 - mae: 4627595.0000 - val_loss: 30121939435520.0000 - val_mae: 5006871.0000\n",
            "Epoch 41/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24427024613376.0000 - mae: 4622392.0000 - val_loss: 30121113157632.0000 - val_mae: 5006803.5000\n",
            "Epoch 42/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25776445456384.0000 - mae: 4739286.0000 - val_loss: 30120234450944.0000 - val_mae: 5006731.0000\n",
            "Epoch 43/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25460205420544.0000 - mae: 4730600.5000 - val_loss: 30119276052480.0000 - val_mae: 5006653.0000\n",
            "Epoch 44/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24780187107328.0000 - mae: 4675178.0000 - val_loss: 30118233767936.0000 - val_mae: 5006568.5000\n",
            "Epoch 45/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25018364854272.0000 - mae: 4686595.5000 - val_loss: 30117132763136.0000 - val_mae: 5006478.5000\n",
            "Epoch 46/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24924414541824.0000 - mae: 4697302.5000 - val_loss: 30115933192192.0000 - val_mae: 5006381.0000\n",
            "Epoch 47/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24107257167872.0000 - mae: 4623848.5000 - val_loss: 30114641346560.0000 - val_mae: 5006276.0000\n",
            "Epoch 48/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24945516085248.0000 - mae: 4698696.5000 - val_loss: 30113284489216.0000 - val_mae: 5006166.5000\n",
            "Epoch 49/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26181411799040.0000 - mae: 4797264.0000 - val_loss: 30111843745792.0000 - val_mae: 5006049.5000\n",
            "Epoch 50/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25034231906304.0000 - mae: 4714924.5000 - val_loss: 30110266687488.0000 - val_mae: 5005922.0000\n",
            "Epoch 51/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25117553852416.0000 - mae: 4668491.0000 - val_loss: 30108635103232.0000 - val_mae: 5005790.0000\n",
            "Epoch 52/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24816272801792.0000 - mae: 4670452.0000 - val_loss: 30106883981312.0000 - val_mae: 5005648.5000\n",
            "Epoch 53/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25149902422016.0000 - mae: 4707090.5000 - val_loss: 30104994447360.0000 - val_mae: 5005496.0000\n",
            "Epoch 54/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24881739595776.0000 - mae: 4652658.0000 - val_loss: 30103033610240.0000 - val_mae: 5005337.0000\n",
            "Epoch 55/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24770101903360.0000 - mae: 4665311.0000 - val_loss: 30100923875328.0000 - val_mae: 5005167.0000\n",
            "Epoch 56/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24899137568768.0000 - mae: 4682665.0000 - val_loss: 30098658951168.0000 - val_mae: 5004985.0000\n",
            "Epoch 57/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25744856055808.0000 - mae: 4744224.5000 - val_loss: 30096264003584.0000 - val_mae: 5004792.0000\n",
            "Epoch 58/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24804170137600.0000 - mae: 4676889.5000 - val_loss: 30093732741120.0000 - val_mae: 5004588.5000\n",
            "Epoch 59/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24538909769728.0000 - mae: 4632077.5000 - val_loss: 30091044192256.0000 - val_mae: 5004372.5000\n",
            "Epoch 60/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25162328047616.0000 - mae: 4701008.5000 - val_loss: 30088252882944.0000 - val_mae: 5004148.5000\n",
            "Epoch 61/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25035890753536.0000 - mae: 4676795.0000 - val_loss: 30085297995776.0000 - val_mae: 5003910.5000\n",
            "Epoch 62/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24508056469504.0000 - mae: 4649998.0000 - val_loss: 30082162753536.0000 - val_mae: 5003658.5000\n",
            "Epoch 63/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24437818654720.0000 - mae: 4637874.0000 - val_loss: 30078840864768.0000 - val_mae: 5003392.5000\n",
            "Epoch 64/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25878425763840.0000 - mae: 4757391.0000 - val_loss: 30075376369664.0000 - val_mae: 5003115.0000\n",
            "Epoch 65/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25287507050496.0000 - mae: 4711585.5000 - val_loss: 30071702159360.0000 - val_mae: 5002821.5000\n",
            "Epoch 66/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25364178927616.0000 - mae: 4720919.0000 - val_loss: 30067793068032.0000 - val_mae: 5002508.5000\n",
            "Epoch 67/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24671672074240.0000 - mae: 4683372.0000 - val_loss: 30063672164352.0000 - val_mae: 5002180.0000\n",
            "Epoch 68/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25681780015104.0000 - mae: 4757447.0000 - val_loss: 30059454791680.0000 - val_mae: 5001842.0000\n",
            "Epoch 69/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25150049222656.0000 - mae: 4685775.5000 - val_loss: 30054964789248.0000 - val_mae: 5001483.5000\n",
            "Epoch 70/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25119414026240.0000 - mae: 4685217.0000 - val_loss: 30050193768448.0000 - val_mae: 5001102.5000\n",
            "Epoch 71/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24121467469824.0000 - mae: 4614471.0000 - val_loss: 30045227712512.0000 - val_mae: 5000706.5000\n",
            "Epoch 72/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24641301118976.0000 - mae: 4654709.0000 - val_loss: 30040079204352.0000 - val_mae: 5000296.0000\n",
            "Epoch 73/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25039061647360.0000 - mae: 4680302.0000 - val_loss: 30034681135104.0000 - val_mae: 4999866.0000\n",
            "Epoch 74/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24461766033408.0000 - mae: 4655348.0000 - val_loss: 30029102710784.0000 - val_mae: 4999421.0000\n",
            "Epoch 75/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24251618820096.0000 - mae: 4627435.0000 - val_loss: 30023136313344.0000 - val_mae: 4998946.5000\n",
            "Epoch 76/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 24947432882176.0000 - mae: 4701319.0000 - val_loss: 30016916160512.0000 - val_mae: 4998452.5000\n",
            "Epoch 77/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23816992456704.0000 - mae: 4590817.0000 - val_loss: 30010316423168.0000 - val_mae: 4997927.5000\n",
            "Epoch 78/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 24613075550208.0000 - mae: 4647824.5000 - val_loss: 30003670548480.0000 - val_mae: 4997399.5000\n",
            "Epoch 79/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25353760276480.0000 - mae: 4736349.5000 - val_loss: 29996710100992.0000 - val_mae: 4996845.0000\n",
            "Epoch 80/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 26391655481344.0000 - mae: 4783811.5000 - val_loss: 29989422497792.0000 - val_mae: 4996265.0000\n",
            "Epoch 81/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 24592116613120.0000 - mae: 4638541.5000 - val_loss: 29981518331904.0000 - val_mae: 4995638.5000\n",
            "Epoch 82/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 23303731281920.0000 - mae: 4549766.5000 - val_loss: 29973343633408.0000 - val_mae: 4994990.0000\n",
            "Epoch 83/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 24643528294400.0000 - mae: 4644994.5000 - val_loss: 29965087145984.0000 - val_mae: 4994334.5000\n",
            "Epoch 84/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24660668317696.0000 - mae: 4668318.5000 - val_loss: 29956469948416.0000 - val_mae: 4993650.5000\n",
            "Epoch 85/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24021611577344.0000 - mae: 4606395.5000 - val_loss: 29947294908416.0000 - val_mae: 4992923.0000\n",
            "Epoch 86/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25438332125184.0000 - mae: 4737068.5000 - val_loss: 29938015010816.0000 - val_mae: 4992186.5000\n",
            "Epoch 87/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24978869190656.0000 - mae: 4683079.0000 - val_loss: 29928198242304.0000 - val_mae: 4991409.5000\n",
            "Epoch 88/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25561504153600.0000 - mae: 4731063.5000 - val_loss: 29917892837376.0000 - val_mae: 4990593.0000\n",
            "Epoch 89/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24326856245248.0000 - mae: 4630596.0000 - val_loss: 29907117670400.0000 - val_mae: 4989739.5000\n",
            "Epoch 90/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25327868837888.0000 - mae: 4708722.5000 - val_loss: 29896340406272.0000 - val_mae: 4988885.5000\n",
            "Epoch 91/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24531647332352.0000 - mae: 4636940.0000 - val_loss: 29884776710144.0000 - val_mae: 4987971.0000\n",
            "Epoch 92/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24161546141696.0000 - mae: 4607180.0000 - val_loss: 29872915218432.0000 - val_mae: 4987031.5000\n",
            "Epoch 93/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24200907587584.0000 - mae: 4604381.0000 - val_loss: 29860703502336.0000 - val_mae: 4986062.5000\n",
            "Epoch 94/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23868771139584.0000 - mae: 4577858.0000 - val_loss: 29848038801408.0000 - val_mae: 4985060.0000\n",
            "Epoch 95/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25726535335936.0000 - mae: 4767467.0000 - val_loss: 29835038556160.0000 - val_mae: 4984031.0000\n",
            "Epoch 96/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24638834868224.0000 - mae: 4662405.5000 - val_loss: 29821627269120.0000 - val_mae: 4982966.0000\n",
            "Epoch 97/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23878468370432.0000 - mae: 4574947.5000 - val_loss: 29807213543424.0000 - val_mae: 4981826.5000\n",
            "Epoch 98/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24283357118464.0000 - mae: 4626917.5000 - val_loss: 29792405553152.0000 - val_mae: 4980655.0000\n",
            "Epoch 99/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24646021808128.0000 - mae: 4662156.5000 - val_loss: 29777337516032.0000 - val_mae: 4979460.5000\n",
            "Epoch 100/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24136107687936.0000 - mae: 4602944.0000 - val_loss: 29761793425408.0000 - val_mae: 4978230.5000\n",
            "Epoch 101/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24028498624512.0000 - mae: 4592392.0000 - val_loss: 29745204953088.0000 - val_mae: 4976918.5000\n",
            "Epoch 102/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25308440821760.0000 - mae: 4708511.0000 - val_loss: 29728631160832.0000 - val_mae: 4975605.5000\n",
            "Epoch 103/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25551540584448.0000 - mae: 4712919.5000 - val_loss: 29711470166016.0000 - val_mae: 4974245.5000\n",
            "Epoch 104/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25720512315392.0000 - mae: 4748584.5000 - val_loss: 29693304635392.0000 - val_mae: 4972808.0000\n",
            "Epoch 105/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24678575898624.0000 - mae: 4667142.0000 - val_loss: 29674574970880.0000 - val_mae: 4971324.5000\n",
            "Epoch 106/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24592716398592.0000 - mae: 4642524.0000 - val_loss: 29655107108864.0000 - val_mae: 4969784.5000\n",
            "Epoch 107/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24221170270208.0000 - mae: 4611932.5000 - val_loss: 29634840231936.0000 - val_mae: 4968184.0000\n",
            "Epoch 108/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24415230230528.0000 - mae: 4634339.5000 - val_loss: 29613969375232.0000 - val_mae: 4966535.0000\n",
            "Epoch 109/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24169404170240.0000 - mae: 4613145.0000 - val_loss: 29592620367872.0000 - val_mae: 4964845.0000\n",
            "Epoch 110/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24061526671360.0000 - mae: 4619842.0000 - val_loss: 29570612854784.0000 - val_mae: 4963105.0000\n",
            "Epoch 111/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24986525892608.0000 - mae: 4671844.5000 - val_loss: 29548586467328.0000 - val_mae: 4961358.0000\n",
            "Epoch 112/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25778230132736.0000 - mae: 4772237.5000 - val_loss: 29525817688064.0000 - val_mae: 4959554.5000\n",
            "Epoch 113/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24931551150080.0000 - mae: 4671450.5000 - val_loss: 29501750771712.0000 - val_mae: 4957649.0000\n",
            "Epoch 114/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25670474268672.0000 - mae: 4729029.5000 - val_loss: 29477161664512.0000 - val_mae: 4955701.0000\n",
            "Epoch 115/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24092071690240.0000 - mae: 4596324.0000 - val_loss: 29451301683200.0000 - val_mae: 4953655.0000\n",
            "Epoch 116/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24626979667968.0000 - mae: 4651145.0000 - val_loss: 29424810459136.0000 - val_mae: 4951558.5000\n",
            "Epoch 117/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24965726339072.0000 - mae: 4703191.0000 - val_loss: 29397891416064.0000 - val_mae: 4949424.5000\n",
            "Epoch 118/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24751839903744.0000 - mae: 4658347.0000 - val_loss: 29369974128640.0000 - val_mae: 4947215.5000\n",
            "Epoch 119/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23918916141056.0000 - mae: 4585574.0000 - val_loss: 29340758704128.0000 - val_mae: 4944900.5000\n",
            "Epoch 120/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25405222289408.0000 - mae: 4714276.0000 - val_loss: 29311643942912.0000 - val_mae: 4942588.5000\n",
            "Epoch 121/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24866990325760.0000 - mae: 4671428.0000 - val_loss: 29280987774976.0000 - val_mae: 4940157.5000\n",
            "Epoch 122/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25066760830976.0000 - mae: 4678028.0000 - val_loss: 29249901690880.0000 - val_mae: 4937689.0000\n",
            "Epoch 123/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25350874595328.0000 - mae: 4698960.5000 - val_loss: 29218052243456.0000 - val_mae: 4935156.5000\n",
            "Epoch 124/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25934639923200.0000 - mae: 4741925.0000 - val_loss: 29185296826368.0000 - val_mae: 4932551.5000\n",
            "Epoch 125/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23997886496768.0000 - mae: 4597126.0000 - val_loss: 29151304089600.0000 - val_mae: 4929848.0000\n",
            "Epoch 126/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23256471961600.0000 - mae: 4549093.5000 - val_loss: 29115746877440.0000 - val_mae: 4927022.0000\n",
            "Epoch 127/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24302575419392.0000 - mae: 4610415.0000 - val_loss: 29080497946624.0000 - val_mae: 4924211.5000\n",
            "Epoch 128/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23871633752064.0000 - mae: 4593589.5000 - val_loss: 29043959267328.0000 - val_mae: 4921299.5000\n",
            "Epoch 129/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24301245825024.0000 - mae: 4630241.5000 - val_loss: 29006273445888.0000 - val_mae: 4918296.5000\n",
            "Epoch 130/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25135964749824.0000 - mae: 4698560.0000 - val_loss: 28968579235840.0000 - val_mae: 4915287.0000\n",
            "Epoch 131/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24706155544576.0000 - mae: 4648728.5000 - val_loss: 28928930480128.0000 - val_mae: 4912124.5000\n",
            "Epoch 132/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22876396716032.0000 - mae: 4499114.0000 - val_loss: 28886398140416.0000 - val_mae: 4908740.5000\n",
            "Epoch 133/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24140603981824.0000 - mae: 4615771.0000 - val_loss: 28845044400128.0000 - val_mae: 4905440.0000\n",
            "Epoch 134/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25342142054400.0000 - mae: 4740430.5000 - val_loss: 28802228944896.0000 - val_mae: 4902020.5000\n",
            "Epoch 135/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23527442874368.0000 - mae: 4566023.5000 - val_loss: 28757194702848.0000 - val_mae: 4898429.0000\n",
            "Epoch 136/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23237176066048.0000 - mae: 4533269.0000 - val_loss: 28711659241472.0000 - val_mae: 4894784.5000\n",
            "Epoch 137/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24672534003712.0000 - mae: 4653417.0000 - val_loss: 28665163284480.0000 - val_mae: 4891064.0000\n",
            "Epoch 138/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24625897537536.0000 - mae: 4660246.5000 - val_loss: 28618411474944.0000 - val_mae: 4887319.5000\n",
            "Epoch 139/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23492103766016.0000 - mae: 4573438.5000 - val_loss: 28568585240576.0000 - val_mae: 4883326.0000\n",
            "Epoch 140/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24107244584960.0000 - mae: 4593353.0000 - val_loss: 28519667073024.0000 - val_mae: 4879399.5000\n",
            "Epoch 141/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23715486105600.0000 - mae: 4588225.0000 - val_loss: 28467519291392.0000 - val_mae: 4875221.0000\n",
            "Epoch 142/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23425290600448.0000 - mae: 4530811.0000 - val_loss: 28415090491392.0000 - val_mae: 4871006.0000\n",
            "Epoch 143/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23304387690496.0000 - mae: 4524509.0000 - val_loss: 28361323708416.0000 - val_mae: 4866684.0000\n",
            "Epoch 144/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 23066836992000.0000 - mae: 4526304.5000 - val_loss: 28306699190272.0000 - val_mae: 4862279.5000\n",
            "Epoch 145/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 23447063232512.0000 - mae: 4570630.0000 - val_loss: 28250241761280.0000 - val_mae: 4857732.0000\n",
            "Epoch 146/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24670862573568.0000 - mae: 4655696.5000 - val_loss: 28193593491456.0000 - val_mae: 4853155.5000\n",
            "Epoch 147/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24141314916352.0000 - mae: 4616346.5000 - val_loss: 28134646743040.0000 - val_mae: 4848395.0000\n",
            "Epoch 148/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23873235976192.0000 - mae: 4590903.0000 - val_loss: 28073672048640.0000 - val_mae: 4843466.5000\n",
            "Epoch 149/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 23954251055104.0000 - mae: 4599927.0000 - val_loss: 28013263585280.0000 - val_mae: 4838570.5000\n",
            "Epoch 150/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23909225201664.0000 - mae: 4598843.5000 - val_loss: 27949495484416.0000 - val_mae: 4833402.5000\n",
            "Epoch 151/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24053479899136.0000 - mae: 4612150.5000 - val_loss: 27886276837376.0000 - val_mae: 4828263.5000\n",
            "Epoch 152/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 22785858469888.0000 - mae: 4482482.0000 - val_loss: 27820325601280.0000 - val_mae: 4822901.0000\n",
            "Epoch 153/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23753465528320.0000 - mae: 4558682.0000 - val_loss: 27753424355328.0000 - val_mae: 4817452.5000\n",
            "Epoch 154/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22961213931520.0000 - mae: 4523379.5000 - val_loss: 27683956195328.0000 - val_mae: 4811794.0000\n",
            "Epoch 155/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23382189932544.0000 - mae: 4552824.0000 - val_loss: 27613596745728.0000 - val_mae: 4806048.5000\n",
            "Epoch 156/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23788479578112.0000 - mae: 4581043.0000 - val_loss: 27543530897408.0000 - val_mae: 4800314.0000\n",
            "Epoch 157/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 22558988566528.0000 - mae: 4472745.0000 - val_loss: 27469369311232.0000 - val_mae: 4794245.5000\n",
            "Epoch 158/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23599773646848.0000 - mae: 4555425.5000 - val_loss: 27396709285888.0000 - val_mae: 4788275.5000\n",
            "Epoch 159/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23981912489984.0000 - mae: 4575781.0000 - val_loss: 27320454742016.0000 - val_mae: 4782008.0000\n",
            "Epoch 160/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22302724980736.0000 - mae: 4437465.0000 - val_loss: 27241490677760.0000 - val_mae: 4775524.0000\n",
            "Epoch 161/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 21600957104128.0000 - mae: 4396354.5000 - val_loss: 27159626252288.0000 - val_mae: 4768799.5000\n",
            "Epoch 162/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 23507750617088.0000 - mae: 4537719.5000 - val_loss: 27080366489600.0000 - val_mae: 4762249.0000\n",
            "Epoch 163/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 23185737121792.0000 - mae: 4541096.5000 - val_loss: 26998290251776.0000 - val_mae: 4755459.0000\n",
            "Epoch 164/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22170226917376.0000 - mae: 4420864.0000 - val_loss: 26913047314432.0000 - val_mae: 4748397.0000\n",
            "Epoch 165/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21983429394432.0000 - mae: 4410675.0000 - val_loss: 26824660746240.0000 - val_mae: 4741070.0000\n",
            "Epoch 166/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21295886499840.0000 - mae: 4348215.5000 - val_loss: 26734934097920.0000 - val_mae: 4733625.0000\n",
            "Epoch 167/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21830421184512.0000 - mae: 4412974.0000 - val_loss: 26646260219904.0000 - val_mae: 4726239.0000\n",
            "Epoch 168/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22049542111232.0000 - mae: 4414490.0000 - val_loss: 26555990409216.0000 - val_mae: 4718714.0000\n",
            "Epoch 169/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22692640063488.0000 - mae: 4475266.5000 - val_loss: 26465181630464.0000 - val_mae: 4711108.5000\n",
            "Epoch 170/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23720531853312.0000 - mae: 4574320.0000 - val_loss: 26370491023360.0000 - val_mae: 4703166.0000\n",
            "Epoch 171/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21860056039424.0000 - mae: 4416124.0000 - val_loss: 26273623572480.0000 - val_mae: 4695031.0000\n",
            "Epoch 172/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21025324531712.0000 - mae: 4308459.5000 - val_loss: 26173818011648.0000 - val_mae: 4686632.0000\n",
            "Epoch 173/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 21433958793216.0000 - mae: 4359042.5000 - val_loss: 26073681100800.0000 - val_mae: 4678178.5000\n",
            "Epoch 174/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 20683729928192.0000 - mae: 4282540.0000 - val_loss: 25970140512256.0000 - val_mae: 4669428.5000\n",
            "Epoch 175/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21516485918720.0000 - mae: 4366479.0000 - val_loss: 25866430054400.0000 - val_mae: 4660627.0000\n",
            "Epoch 176/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 22360621056000.0000 - mae: 4457209.5000 - val_loss: 25762772025344.0000 - val_mae: 4651808.5000\n",
            "Epoch 177/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20954459668480.0000 - mae: 4316899.0000 - val_loss: 25652776402944.0000 - val_mae: 4642435.5000\n",
            "Epoch 178/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 20258691743744.0000 - mae: 4246778.5000 - val_loss: 25543579795456.0000 - val_mae: 4633108.5000\n",
            "Epoch 179/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20820231454720.0000 - mae: 4301612.0000 - val_loss: 25432185372672.0000 - val_mae: 4623562.0000\n",
            "Epoch 180/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21237715697664.0000 - mae: 4349335.5000 - val_loss: 25318679117824.0000 - val_mae: 4613813.5000\n",
            "Epoch 181/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20386227945472.0000 - mae: 4266440.0000 - val_loss: 25202616434688.0000 - val_mae: 4603812.0000\n",
            "Epoch 182/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19958767550464.0000 - mae: 4225746.0000 - val_loss: 25082017611776.0000 - val_mae: 4593406.0000\n",
            "Epoch 183/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20923998535680.0000 - mae: 4334835.5000 - val_loss: 24963065053184.0000 - val_mae: 4583091.0000\n",
            "Epoch 184/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21284498964480.0000 - mae: 4316547.0000 - val_loss: 24841415557120.0000 - val_mae: 4572504.5000\n",
            "Epoch 185/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20111511519232.0000 - mae: 4217109.5000 - val_loss: 24716028936192.0000 - val_mae: 4561589.0000\n",
            "Epoch 186/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 21290087874560.0000 - mae: 4331206.0000 - val_loss: 24591233712128.0000 - val_mae: 4550673.5000\n",
            "Epoch 187/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19939383574528.0000 - mae: 4231773.0000 - val_loss: 24461937999872.0000 - val_mae: 4539334.0000\n",
            "Epoch 188/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20578570338304.0000 - mae: 4271776.0000 - val_loss: 24333191741440.0000 - val_mae: 4527996.0000\n",
            "Epoch 189/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20158710022144.0000 - mae: 4227068.0000 - val_loss: 24199758348288.0000 - val_mae: 4516217.0000\n",
            "Epoch 190/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20011970199552.0000 - mae: 4220015.0000 - val_loss: 24066264137728.0000 - val_mae: 4504363.0000\n",
            "Epoch 191/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 20738436235264.0000 - mae: 4306462.0000 - val_loss: 23930890878976.0000 - val_mae: 4492323.0000\n",
            "Epoch 192/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19242445438976.0000 - mae: 4154748.2500 - val_loss: 23788917882880.0000 - val_mae: 4479655.5000\n",
            "Epoch 193/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 19494948831232.0000 - mae: 4175028.2500 - val_loss: 23648404504576.0000 - val_mae: 4467052.0000\n",
            "Epoch 194/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20037695963136.0000 - mae: 4213275.5000 - val_loss: 23507324895232.0000 - val_mae: 4454344.0000\n",
            "Epoch 195/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19316548304896.0000 - mae: 4158974.5000 - val_loss: 23360809467904.0000 - val_mae: 4441120.5000\n",
            "Epoch 196/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19537273552896.0000 - mae: 4170652.2500 - val_loss: 23216712056832.0000 - val_mae: 4428028.0000\n",
            "Epoch 197/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19760362291200.0000 - mae: 4184116.2500 - val_loss: 23069554900992.0000 - val_mae: 4414608.5000\n",
            "Epoch 198/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19499046666240.0000 - mae: 4166954.7500 - val_loss: 22918880821248.0000 - val_mae: 4400819.5000\n",
            "Epoch 199/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18980616011776.0000 - mae: 4119370.7500 - val_loss: 22764228444160.0000 - val_mae: 4386609.5000\n",
            "Epoch 200/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19149212352512.0000 - mae: 4135069.0000 - val_loss: 22606289829888.0000 - val_mae: 4372022.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 18722288828416.0000\n",
            "Testing MSE: 22606291927040.0000\n",
            "Training RMAE: 2022.2636\n",
            "Testing RMAE: 2090.9382\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "Predicted Housing Price: 1290255.00\n"
          ]
        }
      ]
    }
  ]
}