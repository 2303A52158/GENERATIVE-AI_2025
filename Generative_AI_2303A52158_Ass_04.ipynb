{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/HGPcepSVwW98zL5XBk9Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52158/GENERATIVE-AI_2025/blob/main/Generative_AI_2303A52158_Ass_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a linear activation function in the output layer.**\n",
        "\n",
        "**• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.**\n",
        "\n",
        "**• Calculate the mean square error with training and testing data shown in Table 2.**\n",
        "\n",
        "**• Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        "output with deployed ANN model**\n",
        "\n",
        "                               Tabela 1: Training Data\n",
        "                                x1    x2    x3     y\n",
        "                                0.1   0.2   0.3   0.14\n",
        "                                0.2   0.3   0.4   0.20\n",
        "                                0.3   0.4   0.5   0.26\n",
        "                                0.5   0.6   0.7   0.38\n",
        "                                0.1   0.3   0.5   0.22\n",
        "                                0.2   0.4   0.6   0.28\n",
        "                                0.3   0.5   0.7   0.34\n",
        "                                0.4   0.6   0.8   0.40\n",
        "                                0.5   0.7   0.1   0.22\n",
        "\n",
        "\n",
        "                                Tabela 2: Test Data\n",
        "                                x1    x2    x3     y\n",
        "                                0.6   0.7   0.8   0.44\n",
        "                                0.7   0.8   0.9   0.50\n",
        "                                "
      ],
      "metadata": {
        "id": "cXbTeMfb4HsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t208-IKS2FJ5",
        "outputId": "0648bdc2-a453-4d3d-d0f7-bf3228f11412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error: 0.00014289727084237046\n",
            "Enter x1, x2, x3: 0.1 0.2 0.3 \n",
            "Predicted Output: 0.1436966782227462\n"
          ]
        }
      ],
      "source": [
        "# Simple ANN with Gradient Descent for Training and Prediction\n",
        "training_data = [\n",
        "    (0.1, 0.2, 0.3, 0.14), (0.2, 0.3, 0.4, 0.20), (0.3, 0.4, 0.5, 0.26),\n",
        "    (0.5, 0.6, 0.7, 0.38), (0.1, 0.3, 0.5, 0.22), (0.2, 0.4, 0.6, 0.28),\n",
        "    (0.3, 0.5, 0.7, 0.34), (0.4, 0.6, 0.8, 0.40), (0.5, 0.7, 0.1, 0.22)\n",
        "]\n",
        "\n",
        "test_data = [(0.6, 0.7, 0.8, 0.44), (0.7, 0.8, 0.9, 0.50)]\n",
        "\n",
        "w1, w2, w3, b = 1.0, 1.0, 1.0, 1.0\n",
        "learning_rate = 0.01\n",
        "max_iters = 1000\n",
        "\n",
        "for _ in range(max_iters):\n",
        "    total_error = 0\n",
        "    for x1, x2, x3, y in training_data:\n",
        "        y_pred = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "        error = (y - y_pred) ** 2\n",
        "        total_error += error\n",
        "\n",
        "        grad_w1 = -2 * x1 * (y - y_pred)\n",
        "        grad_w2 = -2 * x2 * (y - y_pred)\n",
        "        grad_w3 = -2 * x3 * (y - y_pred)\n",
        "        grad_b = -2 * (y - y_pred)\n",
        "\n",
        "        w1 -= learning_rate * grad_w1\n",
        "        w2 -= learning_rate * grad_w2\n",
        "        w3 -= learning_rate * grad_w3\n",
        "        b -= learning_rate * grad_b\n",
        "\n",
        "test_error = sum((y - (w1 * x1 + w2 * x2 + w3 * x3 + b)) ** 2 for x1, x2, x3, y in test_data) / len(test_data)\n",
        "print(\"Test Mean Squared Error:\", test_error)\n",
        "\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "predicted_output = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "print(\"Predicted Output:\", predicted_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a sigmoid activation function shown in the equation 1 in the output layer.\n",
        "f(x) = 1\n",
        "1 + e\n",
        "−x**\n",
        "\n",
        "**• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "3.**\n",
        "\n",
        "                      Tabela 1: Training Data\n",
        "                        x1    x2    x3     y\n",
        "                        0.1   0.2   0.3    0.5349\n",
        "                        0.2   0.3   0.4    0.5498\n",
        "                        0.3   0.4   0.5    0.5646\n",
        "                        0.5   0.6   0.7    0.5939\n",
        "                        0.1   0.3   0.5    0.5548\n",
        "                        0.2   0.4   0.6    0.5695\n",
        "                        0.3   0.5   0.7    0.5842\n",
        "                        0.4   0.6   0.8    0.5987\n",
        "                        0.5   0.7   0.1    0.5548\n",
        "\n",
        "                        Tabela 1: Test Data\n",
        "                        x1    x2    x3     y\n",
        "                        0.6   0.7    0.8   0.6083\n",
        "                        0.7   0.8    0.9   0.6225\n",
        "\n",
        "**• Calculate the mean square error with training and testing data shown in Table 4.**\n",
        "\n",
        "**• Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        "output with deployed ANN model**\n"
      ],
      "metadata": {
        "id": "eVPO-A7w82GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple ANN with Sigmoid Activation and Gradient Descent\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + 2.71828**-x)\n",
        "\n",
        "training_data = [\n",
        "    (0.1, 0.2, 0.3, 0.5349), (0.2, 0.3, 0.4, 0.5498), (0.3, 0.4, 0.5, 0.5646),\n",
        "    (0.5, 0.6, 0.7, 0.5939), (0.1, 0.3, 0.5, 0.5548), (0.2, 0.4, 0.6, 0.5695),\n",
        "    (0.3, 0.5, 0.7, 0.5842), (0.4, 0.6, 0.8, 0.5987), (0.5, 0.7, 0.1, 0.5548)\n",
        "]\n",
        "\n",
        "test_data = [(0.6, 0.7, 0.8, 0.6083), (0.7, 0.8, 0.9, 0.6225)]\n",
        "\n",
        "w1, w2, w3, b = 1.0, 1.0, 1.0, 1.0\n",
        "learning_rate = 0.01\n",
        "max_iters = 1000\n",
        "\n",
        "for _ in range(max_iters):\n",
        "    total_error = 0\n",
        "    for x1, x2, x3, y in training_data:\n",
        "        z = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "        y_pred = sigmoid(z)\n",
        "        error = (y - y_pred) ** 2\n",
        "        total_error += error\n",
        "\n",
        "        grad_y_pred = -2 * (y - y_pred) * y_pred * (1 - y_pred)\n",
        "        grad_w1 = grad_y_pred * x1\n",
        "        grad_w2 = grad_y_pred * x2\n",
        "        grad_w3 = grad_y_pred * x3\n",
        "        grad_b = grad_y_pred\n",
        "\n",
        "        w1 -= learning_rate * grad_w1\n",
        "        w2 -= learning_rate * grad_w2\n",
        "        w3 -= learning_rate * grad_w3\n",
        "        b -= learning_rate * grad_b\n",
        "\n",
        "test_error = sum((y - sigmoid(w1 * x1 + w2 * x2 + w3 * x3 + b)) ** 2 for x1, x2, x3, y in test_data) / len(test_data)\n",
        "print(\"Test Mean Squared Error:\", test_error)\n",
        "\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "predicted_output = sigmoid(w1 * x1 + w2 * x2 + w3 * x3 + b)\n",
        "print(\"Predicted Output:\", predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBWE_Iab8jso",
        "outputId": "863bc02a-9d56-4640-bbf3-d95307247002"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error: 0.0023101380705057148\n",
            "Enter x1, x2, x3: 0.1 0.2 0.3\n",
            "Predicted Output: 0.5027511991256228\n"
          ]
        }
      ]
    }
  ]
}